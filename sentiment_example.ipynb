{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the environment\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A very, very, very slow-moving, aimless movie about a distressed, drifting young man.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not sure who was more lost - the flat characters or the audience, nearly half of whom walked out.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Attempting artiness with black &amp; white and clever camera angles, the movie disappointed - became even more ridiculous - as the acting was poor and the plot and lines almost non-existent.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Very little music or anything to speak of.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The best scene in the movie was when Gerardo is trying to find a song that keeps running through his head.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                           text  \\\n",
       "0                                                                                                       A very, very, very slow-moving, aimless movie about a distressed, drifting young man.     \n",
       "1                                                                                           Not sure who was more lost - the flat characters or the audience, nearly half of whom walked out.     \n",
       "2  Attempting artiness with black & white and clever camera angles, the movie disappointed - became even more ridiculous - as the acting was poor and the plot and lines almost non-existent.     \n",
       "3                                                                                                                                                  Very little music or anything to speak of.     \n",
       "4                                                                                  The best scene in the movie was when Gerardo is trying to find a song that keeps running through his head.     \n",
       "\n",
       "   label  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      1  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv(r'/home/brian/Documents/tweetf/tweets.csv')\n",
    "\n",
    "# Make the columns viewable\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the no of each label to check on balance\n",
    "df['label'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take first text entry\n",
    "sample = df.text[0]\n",
    "sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import a tokenizer\n",
    "from nltk import word_tokenize\n",
    "\n",
    "# Tokenize the sample\n",
    "sample_tokens = word_tokenize(sample)\n",
    "\n",
    "# Return the tokens\n",
    "sample_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the package\n",
    "from nltk import bigrams\n",
    "\n",
    "# Create the bigrams\n",
    "sample_bitokens = list(bigrams(sample_tokens))\n",
    "\n",
    "# Return the bigrams\n",
    "sample_bitokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the frequency of occurrence of tokens\n",
    "from nltk import FreqDist\n",
    "\n",
    "# Create a frequency distro for the tokens\n",
    "sample_distro = FreqDist(sample_tokens)\n",
    "\n",
    "# Return the top 10\n",
    "sample_distro.most_common(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 2), ('Loved', 1), ('casting', 1), ('of', 1), ('Jimmy', 1)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a function to do all this\n",
    "def token_analyze(text, n):\n",
    "\n",
    "    # Create tokens\n",
    "    uni_tokens = word_tokenize(text)\n",
    "\n",
    "    # Create a freq distro\n",
    "    distro_freq = FreqDist(uni_tokens)\n",
    "\n",
    "    # Return the n metric\n",
    "    return distro_freq.most_common(n)\n",
    "\n",
    "\n",
    "token_analyze(df.text[9], 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>about</th>\n",
       "      <th>acting</th>\n",
       "      <th>aimless</th>\n",
       "      <th>almost</th>\n",
       "      <th>and</th>\n",
       "      <th>angles</th>\n",
       "      <th>anything</th>\n",
       "      <th>artiness</th>\n",
       "      <th>as</th>\n",
       "      <th>attempting</th>\n",
       "      <th>...</th>\n",
       "      <th>trying</th>\n",
       "      <th>very</th>\n",
       "      <th>walked</th>\n",
       "      <th>was</th>\n",
       "      <th>when</th>\n",
       "      <th>white</th>\n",
       "      <th>who</th>\n",
       "      <th>whom</th>\n",
       "      <th>with</th>\n",
       "      <th>young</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   about  acting  aimless  almost  and  angles  anything  artiness  as  \\\n",
       "0      1       0        1       0    0       0         0         0   0   \n",
       "1      0       0        0       0    0       0         0         0   0   \n",
       "2      0       1        0       1    3       1         0         1   1   \n",
       "3      0       0        0       0    0       0         1         0   0   \n",
       "4      0       0        0       0    0       0         0         0   0   \n",
       "\n",
       "   attempting  ...  trying  very  walked  was  when  white  who  whom  with  \\\n",
       "0           0  ...       0     3       0    0     0      0    0     0     0   \n",
       "1           0  ...       0     0       1    1     0      0    1     1     0   \n",
       "2           1  ...       0     0       0    1     0      1    0     0     1   \n",
       "3           0  ...       0     1       0    0     0      0    0     0     0   \n",
       "4           0  ...       1     0       0    1     1      0    0     0     0   \n",
       "\n",
       "   young  \n",
       "0      1  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  \n",
       "\n",
       "[5 rows x 68 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "def create_dtm(series):\n",
    "\n",
    "    # Create the instance of a class\n",
    "    cv = CountVectorizer()\n",
    "\n",
    "    # Create a DTM from the provided series\n",
    "    dtm = cv.fit_transform(series)\n",
    "\n",
    "    # Convert the sparse array into a dense array\n",
    "    dtm = dtm.todense()\n",
    "\n",
    "    # Get column names\n",
    "    features = cv.get_feature_names_out()\n",
    "\n",
    "    # Create a dataframe\n",
    "    dtm_df = pd.DataFrame(dtm, columns=features)\n",
    "\n",
    "    return dtm_df\n",
    "\n",
    "\n",
    "# Try it out\n",
    "create_dtm(df.text.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1567</th>\n",
       "      <td>liked</td>\n",
       "      <td>1.286747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>wonderful</td>\n",
       "      <td>1.242158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1104</th>\n",
       "      <td>funny</td>\n",
       "      <td>1.112821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182</th>\n",
       "      <td>great</td>\n",
       "      <td>1.068772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2949</th>\n",
       "      <td>well</td>\n",
       "      <td>1.043139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>beautiful</td>\n",
       "      <td>1.042833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>1.035405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>brilliant</td>\n",
       "      <td>1.014080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>908</th>\n",
       "      <td>excellent</td>\n",
       "      <td>1.009914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2203</th>\n",
       "      <td>right</td>\n",
       "      <td>0.985806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Tokens  Coefficients\n",
       "1567      liked      1.286747\n",
       "2997  wonderful      1.242158\n",
       "1104      funny      1.112821\n",
       "1182      great      1.068772\n",
       "2949       well      1.043139\n",
       "246   beautiful      1.042833\n",
       "0            10      1.035405\n",
       "344   brilliant      1.014080\n",
       "908   excellent      1.009914\n",
       "2203      right      0.985806"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "def top_tokens(text, sentiment, n):\n",
    "    # Create an instance of the class\n",
    "    lgr = LogisticRegression(solver='lbfgs', max_iter=2500, random_state=1234)\n",
    "    cv = CountVectorizer()\n",
    "\n",
    "    # create the DTM\n",
    "    dtm = cv.fit_transform(text)\n",
    "\n",
    "    # Fit the logistic regression model\n",
    "    lgr.fit(dtm, sentiment)\n",
    "\n",
    "    # Get the coefficients\n",
    "    coefs = lgr.coef_[0]\n",
    "\n",
    "    # Create the features / column names\n",
    "    features = cv.get_feature_names_out()\n",
    "\n",
    "    # create the dataframe\n",
    "    df = pd.DataFrame({'Tokens': features, 'Coefficients': coefs})\n",
    "\n",
    "    # Return the largest n\n",
    "    return df.nlargest(n, 'Coefficients')\n",
    "\n",
    "\n",
    "# Test it on the df['text']\n",
    "top_tokens(df.text, df.label, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polarity is:  0.18 and Subjectivity is:  0.4\n"
     ]
    }
   ],
   "source": [
    "# -------------TEXTBLOB----------------\n",
    "# here, the data isn't labelled. The algo determines the sentiment\n",
    "from textblob import TextBlob\n",
    "\n",
    "\n",
    "def polarity_subjectivity(text, print_results=False):\n",
    "    # Create an instance of TextBlob\n",
    "    tb = TextBlob(text)\n",
    "\n",
    "    # If the condition is met, print results, otherwise, return the tuple\n",
    "    if print_results:\n",
    "        print(\"Polarity is: \", round(\n",
    "            tb.sentiment[0], 2), \"and Subjectivity is: \", round(tb.sentiment[1], 2))\n",
    "    else:\n",
    "        return(tb.sentiment[0], tb.sentiment[1])\n",
    "\n",
    "\n",
    "# Test\n",
    "polarity_subjectivity(sample, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    18\n",
       "1    21\n",
       "2    33\n",
       "3     9\n",
       "4    22\n",
       "5    27\n",
       "6     4\n",
       "7    17\n",
       "8     4\n",
       "9    11\n",
       "Name: text, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ------------COUNTING THE NUMBER OF TOKENS------------------\n",
    "\n",
    "from nltk import word_tokenize\n",
    "\n",
    "# A function that counts the no. of tokens in a string\n",
    "\n",
    "\n",
    "def token_count(str):\n",
    "    return len(word_tokenize(str))\n",
    "\n",
    "# A function that counts tokens in a Pandas Series\n",
    "\n",
    "\n",
    "def stoken_count(series):\n",
    "    return series.apply(token_count)\n",
    "\n",
    "\n",
    "# test\n",
    "stoken_count(df.text.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                 (0.18, 0.395)\n",
       "1    (0.014583333333333337, 0.4201388888888889)\n",
       "2    (-0.12291666666666666, 0.5145833333333333)\n",
       "3                  (-0.24375000000000002, 0.65)\n",
       "4                                    (1.0, 0.3)\n",
       "5                                   (-0.1, 0.5)\n",
       "6                                   (-0.2, 0.0)\n",
       "7                     (0.7, 0.6000000000000001)\n",
       "8                                   (-0.2, 0.5)\n",
       "9                                    (0.7, 0.8)\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A function that applies polarity _subjectivity to a column\n",
    "def series_pol_subj(series):\n",
    "    return series.apply(polarity_subjectivity)\n",
    "\n",
    "\n",
    "# Apply to the top 10 rows of our dataframe\n",
    "series_pol_subj(df['text'].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.722222\n",
       "1    0.952381\n",
       "2    0.848485\n",
       "3    1.000000\n",
       "4    1.000000\n",
       "5    0.814815\n",
       "6    1.000000\n",
       "7    0.941176\n",
       "8    1.000000\n",
       "9    0.909091\n",
       "Name: text, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -------------MEASURE OF COMPLEXITY-LEXICAL DIVERSITY----------------\n",
    "\n",
    "def complexity(str):\n",
    "    # Create a list of all tokens\n",
    "    all_tokens = word_tokenize(str)\n",
    "\n",
    "    # Create a set of unique tokens\n",
    "    unique_tokens = set(word_tokenize(str))\n",
    "\n",
    "    # Return the complexity measure\n",
    "    return len(unique_tokens) / len(all_tokens)\n",
    "\n",
    "\n",
    "# test\n",
    "df.text.head(10).apply(complexity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                                                                 [,, ,, slow-moving, ,, aimless, movie, distressed, ,, drifting, young, man, .]\n",
       "1                                                                                                        [sure, lost, -, flat, characters, audience, ,, nearly, half, walked, .]\n",
       "2    [Attempting, artiness, black, &, white, clever, camera, angles, ,, movie, disappointed, -, became, even, ridiculous, -, acting, poor, plot, lines, almost, non-existent, .]\n",
       "3                                                                                                                                            [little, music, anything, speak, .]\n",
       "4                                                                                                     [best, scene, movie, Gerardo, trying, find, song, keeps, running, head, .]\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -----------------TEXT CLEANUP----------------\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "def stopword_remover(str):\n",
    "    # Create tokens\n",
    "    tokens = word_tokenize(str)\n",
    "\n",
    "    # Identify stopwords\n",
    "    eng_stopwords = stopwords.words('english')\n",
    "\n",
    "    # Return non-stopwords\n",
    "    return [w for w in tokens if w.lower() not in eng_stopwords]\n",
    "\n",
    "\n",
    "# test\n",
    "df.text.head(5).apply(stopword_remover)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                                                                [aimless, movie, distressed, drifting, young, man]\n",
       "1                                                                                    [sure, lost, flat, characters, audience, nearly, half, walked]\n",
       "2    [Attempting, artiness, black, white, clever, camera, angles, movie, disappointed, became, even, ridiculous, acting, poor, plot, lines, almost]\n",
       "3                                                                                                                  [little, music, anything, speak]\n",
       "4                                                                           [best, scene, movie, Gerardo, trying, find, song, keeps, running, head]\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ----------REMOVING PUNCTUATION MARKS-----------------\n",
    "\n",
    "def nonalpha_remover(str):\n",
    "    return [x for x in stopword_remover(str) if x.isalpha()]\n",
    "\n",
    "\n",
    "df['text'].head().apply(nonalpha_remover)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'complexity' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/brian/Vscode/LuxTech/machine learning/sentiment_example.ipynb Cell 17\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/brian/Vscode/LuxTech/machine%20learning/sentiment_example.ipynb#X22sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m series\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: complexity(\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(nonalpha_remover(x))))\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/brian/Vscode/LuxTech/machine%20learning/sentiment_example.ipynb#X22sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# Add 'complexity' column to the dataframe\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/brian/Vscode/LuxTech/machine%20learning/sentiment_example.ipynb#X22sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mcomplexity\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m complexity_cleaned(df\u001b[39m.\u001b[39;49mtext)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/brian/Vscode/LuxTech/machine%20learning/sentiment_example.ipynb#X22sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# Return top 10 highest complexity scores\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/brian/Vscode/LuxTech/machine%20learning/sentiment_example.ipynb#X22sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m df\u001b[39m.\u001b[39msort_values([\u001b[39m'\u001b[39m\u001b[39mcomplexity\u001b[39m\u001b[39m'\u001b[39m], ascending\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\u001b[39m.\u001b[39mhead(\u001b[39m10\u001b[39m)\n",
      "\u001b[1;32m/home/brian/Vscode/LuxTech/machine learning/sentiment_example.ipynb Cell 17\u001b[0m in \u001b[0;36mcomplexity_cleaned\u001b[0;34m(series)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/brian/Vscode/LuxTech/machine%20learning/sentiment_example.ipynb#X22sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcomplexity_cleaned\u001b[39m(series):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/brian/Vscode/LuxTech/machine%20learning/sentiment_example.ipynb#X22sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m series\u001b[39m.\u001b[39;49mapply(\u001b[39mlambda\u001b[39;49;00m x: complexity(\u001b[39m'\u001b[39;49m\u001b[39m \u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m.\u001b[39;49mjoin(nonalpha_remover(x))))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/series.py:4433\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4323\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[1;32m   4324\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   4325\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4328\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   4329\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[1;32m   4330\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   4331\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4332\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4431\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4432\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4433\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/apply.py:1082\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1078\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf, \u001b[39mstr\u001b[39m):\n\u001b[1;32m   1079\u001b[0m     \u001b[39m# if we are a string, try to dispatch\u001b[39;00m\n\u001b[1;32m   1080\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[0;32m-> 1082\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/apply.py:1137\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1131\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[1;32m   1132\u001b[0m         \u001b[39m# error: Argument 2 to \"map_infer\" has incompatible type\u001b[39;00m\n\u001b[1;32m   1133\u001b[0m         \u001b[39m# \"Union[Callable[..., Any], str, List[Union[Callable[..., Any], str]],\u001b[39;00m\n\u001b[1;32m   1134\u001b[0m         \u001b[39m# Dict[Hashable, Union[Union[Callable[..., Any], str],\u001b[39;00m\n\u001b[1;32m   1135\u001b[0m         \u001b[39m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m         \u001b[39m# \"Callable[[Any], Any]\"\u001b[39;00m\n\u001b[0;32m-> 1137\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[1;32m   1138\u001b[0m             values,\n\u001b[1;32m   1139\u001b[0m             f,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1140\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[1;32m   1141\u001b[0m         )\n\u001b[1;32m   1143\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1144\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1145\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1146\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/_libs/lib.pyx:2870\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[1;32m/home/brian/Vscode/LuxTech/machine learning/sentiment_example.ipynb Cell 17\u001b[0m in \u001b[0;36mcomplexity_cleaned.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/brian/Vscode/LuxTech/machine%20learning/sentiment_example.ipynb#X22sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcomplexity_cleaned\u001b[39m(series):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/brian/Vscode/LuxTech/machine%20learning/sentiment_example.ipynb#X22sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m series\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: complexity(\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(nonalpha_remover(x))))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'complexity' is not defined"
     ]
    }
   ],
   "source": [
    "# -----------CLEANING COMPLEXITY------------\n",
    "# removing punctuation and stopwords\n",
    "\n",
    "def complexity_cleaned(series):\n",
    "    return series.apply(lambda x: complexity(' '.join(nonalpha_remover(x))))\n",
    "\n",
    "\n",
    "# Add 'complexity' column to the dataframe\n",
    "df['complexity'] = complexity_cleaned(df.text)\n",
    "\n",
    "# Return top 10 highest complexity scores\n",
    "df.sort_values(['complexity'], ascending=False).head(10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
