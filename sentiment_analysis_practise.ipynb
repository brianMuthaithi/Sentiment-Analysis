{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the environment\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A very, very, very slow-moving, aimless movie about a distressed, drifting young man.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not sure who was more lost - the flat characters or the audience, nearly half of whom walked out.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Attempting artiness with black &amp; white and clever camera angles, the movie disappointed - became even more ridiculous - as the acting was poor and the plot and lines almost non-existent.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Very little music or anything to speak of.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The best scene in the movie was when Gerardo is trying to find a song that keeps running through his head.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                           text  \\\n",
       "0                                                                                                       A very, very, very slow-moving, aimless movie about a distressed, drifting young man.     \n",
       "1                                                                                           Not sure who was more lost - the flat characters or the audience, nearly half of whom walked out.     \n",
       "2  Attempting artiness with black & white and clever camera angles, the movie disappointed - became even more ridiculous - as the acting was poor and the plot and lines almost non-existent.     \n",
       "3                                                                                                                                                  Very little music or anything to speak of.     \n",
       "4                                                                                  The best scene in the movie was when Gerardo is trying to find a song that keeps running through his head.     \n",
       "\n",
       "   label  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv('datasets/tweets.csv')\n",
    "\n",
    "# Make the columns viewable\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the no of each label to check on balance\n",
    "df['label'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A very, very, very slow-moving, aimless movie about a distressed, drifting young man.  '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take first text entry\n",
    "sample = df.text[0]\n",
    "sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A', 'very', ',', 'very', ',', 'very', 'slow-moving', ',', 'aimless', 'movie']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import a tokenizer\n",
    "from nltk import word_tokenize\n",
    "\n",
    "# Tokenize the sample\n",
    "sample_tokens = word_tokenize(sample)\n",
    "\n",
    "# Return the tokens\n",
    "sample_tokens[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('A', 'very'),\n",
       " ('very', ','),\n",
       " (',', 'very'),\n",
       " ('very', ','),\n",
       " (',', 'very'),\n",
       " ('very', 'slow-moving'),\n",
       " ('slow-moving', ','),\n",
       " (',', 'aimless'),\n",
       " ('aimless', 'movie'),\n",
       " ('movie', 'about'),\n",
       " ('about', 'a'),\n",
       " ('a', 'distressed'),\n",
       " ('distressed', ','),\n",
       " (',', 'drifting'),\n",
       " ('drifting', 'young'),\n",
       " ('young', 'man'),\n",
       " ('man', '.')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the package\n",
    "from nltk import bigrams\n",
    "\n",
    "# Create the bigrams\n",
    "sample_bitokens = list(bigrams(sample_tokens))\n",
    "\n",
    "# Return the bigrams\n",
    "sample_bitokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 4),\n",
       " ('very', 3),\n",
       " ('A', 1),\n",
       " ('slow-moving', 1),\n",
       " ('aimless', 1),\n",
       " ('movie', 1),\n",
       " ('about', 1),\n",
       " ('a', 1),\n",
       " ('distressed', 1),\n",
       " ('drifting', 1)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the frequency of occurrence of tokens\n",
    "from nltk import FreqDist\n",
    "\n",
    "# Create a frequency distro for the tokens\n",
    "sample_distro = FreqDist(sample_tokens)\n",
    "\n",
    "# Return the top 10\n",
    "sample_distro.most_common(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 2), ('Loved', 1), ('casting', 1), ('of', 1), ('Jimmy', 1)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a function to do all this\n",
    "def token_analyze(text, n):\n",
    "\n",
    "    # Create tokens\n",
    "    uni_tokens = word_tokenize(text)\n",
    "\n",
    "    # Create a freq distro\n",
    "    distro_freq = FreqDist(uni_tokens)\n",
    "\n",
    "    # Return the n metric\n",
    "    return distro_freq.most_common(n)\n",
    "\n",
    "\n",
    "token_analyze(df.text[9], 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>about</th>\n",
       "      <th>acting</th>\n",
       "      <th>aimless</th>\n",
       "      <th>almost</th>\n",
       "      <th>and</th>\n",
       "      <th>angles</th>\n",
       "      <th>anything</th>\n",
       "      <th>artiness</th>\n",
       "      <th>as</th>\n",
       "      <th>attempting</th>\n",
       "      <th>...</th>\n",
       "      <th>trying</th>\n",
       "      <th>very</th>\n",
       "      <th>walked</th>\n",
       "      <th>was</th>\n",
       "      <th>when</th>\n",
       "      <th>white</th>\n",
       "      <th>who</th>\n",
       "      <th>whom</th>\n",
       "      <th>with</th>\n",
       "      <th>young</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   about  acting  aimless  almost  and  angles  anything  artiness  as  \\\n",
       "0      1       0        1       0    0       0         0         0   0   \n",
       "1      0       0        0       0    0       0         0         0   0   \n",
       "2      0       1        0       1    3       1         0         1   1   \n",
       "3      0       0        0       0    0       0         1         0   0   \n",
       "4      0       0        0       0    0       0         0         0   0   \n",
       "\n",
       "   attempting  ...  trying  very  walked  was  when  white  who  whom  with  \\\n",
       "0           0  ...       0     3       0    0     0      0    0     0     0   \n",
       "1           0  ...       0     0       1    1     0      0    1     1     0   \n",
       "2           1  ...       0     0       0    1     0      1    0     0     1   \n",
       "3           0  ...       0     1       0    0     0      0    0     0     0   \n",
       "4           0  ...       1     0       0    1     1      0    0     0     0   \n",
       "\n",
       "   young  \n",
       "0      1  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  \n",
       "\n",
       "[5 rows x 68 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "def create_dtm(series):\n",
    "\n",
    "    # Create the instance of a class\n",
    "    cv = CountVectorizer()\n",
    "\n",
    "    # Create a DTM from the provided series\n",
    "    dtm = cv.fit_transform(series)\n",
    "\n",
    "    # Convert the sparse array into a dense array\n",
    "    dtm = dtm.todense()\n",
    "\n",
    "    # Get column names\n",
    "    features = cv.get_feature_names_out()\n",
    "\n",
    "    # Create a dataframe\n",
    "    dtm_df = pd.DataFrame(dtm, columns=features)\n",
    "\n",
    "    return dtm_df\n",
    "\n",
    "\n",
    "# Try it out\n",
    "create_dtm(df.text.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1567</th>\n",
       "      <td>liked</td>\n",
       "      <td>1.286747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>wonderful</td>\n",
       "      <td>1.242158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1104</th>\n",
       "      <td>funny</td>\n",
       "      <td>1.112821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182</th>\n",
       "      <td>great</td>\n",
       "      <td>1.068772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2949</th>\n",
       "      <td>well</td>\n",
       "      <td>1.043139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>beautiful</td>\n",
       "      <td>1.042833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>1.035405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>brilliant</td>\n",
       "      <td>1.014080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>908</th>\n",
       "      <td>excellent</td>\n",
       "      <td>1.009914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2203</th>\n",
       "      <td>right</td>\n",
       "      <td>0.985806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Tokens  Coefficients\n",
       "1567      liked      1.286747\n",
       "2997  wonderful      1.242158\n",
       "1104      funny      1.112821\n",
       "1182      great      1.068772\n",
       "2949       well      1.043139\n",
       "246   beautiful      1.042833\n",
       "0            10      1.035405\n",
       "344   brilliant      1.014080\n",
       "908   excellent      1.009914\n",
       "2203      right      0.985806"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "def top_tokens(text, sentiment, n):\n",
    "    # Create an instance of the class\n",
    "    lgr = LogisticRegression(solver='lbfgs', max_iter=2500, random_state=1234)\n",
    "    cv = CountVectorizer()\n",
    "\n",
    "    # create the DTM\n",
    "    dtm = cv.fit_transform(text)\n",
    "\n",
    "    # Fit the logistic regression model\n",
    "    lgr.fit(dtm, sentiment)\n",
    "\n",
    "    # Get the coefficients\n",
    "    coefs = lgr.coef_[0]\n",
    "\n",
    "    # Create the features / column names\n",
    "    features = cv.get_feature_names_out()\n",
    "\n",
    "    # create the dataframe\n",
    "    df = pd.DataFrame({'Tokens': features, 'Coefficients': coefs})\n",
    "\n",
    "    # Return the largest n\n",
    "    return df.nlargest(n, 'Coefficients')\n",
    "\n",
    "\n",
    "# Test it on the df['text']\n",
    "top_tokens(df.text, df.label, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polarity is:  0.18 and Subjectivity is:  0.4\n"
     ]
    }
   ],
   "source": [
    "# -------------TEXTBLOB----------------\n",
    "# here, the data isn't labelled. The algo determines the sentiment\n",
    "from textblob import TextBlob\n",
    "\n",
    "\n",
    "def polarity_subjectivity(text, print_results=False):\n",
    "    # Create an instance of TextBlob\n",
    "    tb = TextBlob(text)\n",
    "\n",
    "    # If the condition is met, print results, otherwise, return the tuple\n",
    "    if print_results:\n",
    "        print(\"Polarity is: \", round(\n",
    "            tb.sentiment[0], 2), \"and Subjectivity is: \", round(tb.sentiment[1], 2))\n",
    "    else:\n",
    "        return(tb.sentiment[0], tb.sentiment[1])\n",
    "\n",
    "\n",
    "# Test\n",
    "polarity_subjectivity(sample, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    18\n",
       "1    21\n",
       "2    33\n",
       "3     9\n",
       "4    22\n",
       "5    27\n",
       "6     4\n",
       "7    17\n",
       "8     4\n",
       "9    11\n",
       "Name: text, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ------------COUNTING THE NUMBER OF TOKENS------------------\n",
    "\n",
    "from nltk import word_tokenize\n",
    "\n",
    "# A function that counts the no. of tokens in a string\n",
    "\n",
    "\n",
    "def token_count(str):\n",
    "    return len(word_tokenize(str))\n",
    "\n",
    "# A function that counts tokens in a Pandas Series\n",
    "\n",
    "\n",
    "def stoken_count(series):\n",
    "    return series.apply(token_count)\n",
    "\n",
    "\n",
    "# test\n",
    "stoken_count(df.text.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                 (0.18, 0.395)\n",
       "1    (0.014583333333333337, 0.4201388888888889)\n",
       "2    (-0.12291666666666666, 0.5145833333333333)\n",
       "3                  (-0.24375000000000002, 0.65)\n",
       "4                                    (1.0, 0.3)\n",
       "5                                   (-0.1, 0.5)\n",
       "6                                   (-0.2, 0.0)\n",
       "7                     (0.7, 0.6000000000000001)\n",
       "8                                   (-0.2, 0.5)\n",
       "9                                    (0.7, 0.8)\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A function that applies polarity _subjectivity to a column\n",
    "def series_pol_subj(series):\n",
    "    return series.apply(polarity_subjectivity)\n",
    "\n",
    "\n",
    "# Apply to the top 10 rows of our dataframe\n",
    "series_pol_subj(df['text'].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.722222\n",
       "1    0.952381\n",
       "2    0.848485\n",
       "3    1.000000\n",
       "4    1.000000\n",
       "5    0.814815\n",
       "6    1.000000\n",
       "7    0.941176\n",
       "8    1.000000\n",
       "9    0.909091\n",
       "Name: text, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -------------MEASURE OF COMPLEXITY-LEXICAL DIVERSITY----------------\n",
    "\n",
    "def complexity(str):\n",
    "    # Create a list of all tokens\n",
    "    all_tokens = word_tokenize(str)\n",
    "\n",
    "    # Create a set of unique tokens\n",
    "    unique_tokens = set(word_tokenize(str))\n",
    "\n",
    "    # Return the complexity measure\n",
    "    return len(unique_tokens) / len(all_tokens)\n",
    "\n",
    "\n",
    "# test\n",
    "df.text.head(10).apply(complexity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                                                                 [,, ,, slow-moving, ,, aimless, movie, distressed, ,, drifting, young, man, .]\n",
       "1                                                                                                        [sure, lost, -, flat, characters, audience, ,, nearly, half, walked, .]\n",
       "2    [Attempting, artiness, black, &, white, clever, camera, angles, ,, movie, disappointed, -, became, even, ridiculous, -, acting, poor, plot, lines, almost, non-existent, .]\n",
       "3                                                                                                                                            [little, music, anything, speak, .]\n",
       "4                                                                                                     [best, scene, movie, Gerardo, trying, find, song, keeps, running, head, .]\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -----------------TEXT CLEANUP----------------\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "def stopword_remover(str):\n",
    "    # Create tokens\n",
    "    tokens = word_tokenize(str)\n",
    "\n",
    "    # Identify stopwords\n",
    "    eng_stopwords = stopwords.words('english')\n",
    "\n",
    "    # Return non-stopwords\n",
    "    return [w for w in tokens if w.lower() not in eng_stopwords]\n",
    "\n",
    "\n",
    "# test\n",
    "df.text.head(5).apply(stopword_remover)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                                                                [aimless, movie, distressed, drifting, young, man]\n",
       "1                                                                                    [sure, lost, flat, characters, audience, nearly, half, walked]\n",
       "2    [Attempting, artiness, black, white, clever, camera, angles, movie, disappointed, became, even, ridiculous, acting, poor, plot, lines, almost]\n",
       "3                                                                                                                  [little, music, anything, speak]\n",
       "4                                                                           [best, scene, movie, Gerardo, trying, find, song, keeps, running, head]\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ----------REMOVING PUNCTUATION MARKS-----------------\n",
    "\n",
    "def nonalpha_remover(str):\n",
    "    return [x for x in stopword_remover(str) if x.isalpha()]\n",
    "\n",
    "\n",
    "df['text'].head().apply(nonalpha_remover)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------CLEANING COMPLEXITY------------\n",
    "# removing punctuation and stopwords\n",
    "\n",
    "def complexity_cleaned(series):\n",
    "    return series.apply(lambda x: complexity(' '.join(nonalpha_remover(x))))\n",
    "\n",
    "\n",
    "# Add 'complexity' column to the dataframe\n",
    "df['complexity'] = complexity_cleaned(df.text)\n",
    "\n",
    "# Return top 10 highest complexity scores\n",
    "df.sort_values(['complexity'], ascending=False).head(10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
